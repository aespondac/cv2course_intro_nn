{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descenso por gradiente\n",
    "\n",
    "En este notebook implementaremos un solo paso del método de descenso por gradiente. El método es una técnica de optimización utilizada para encontrar el mínimo de una función de manera iterativa. En el contexto de redes neuronales, se utiliza para minimizar la función de costo, que mide el error entre las predicciones del modelo y los valores reales. El proceso comienza con una estimación inicial para los parámetros del modelo, y luego, en cada paso, ajusta estos parámetros en la dirección opuesta al gradiente de la función de costo, que indica la dirección de mayor aumento. La magnitud del ajuste en cada paso se determina por un parámetro llamado tasa de aprendizaje. El proceso se repite hasta alcanzar un mínimo local o hasta que el cambio en la función de costo entre iteraciones sea insignificante, indicando que el modelo ha convergido a una solución.\n",
    "\n",
    "![gradiente](files/gradient_descent_1n_notebook.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/irvingvasquez/cv2course_intro_nn/blob/master/03_descenso_unpaso.ipynb)\n",
    "\n",
    "@juan1rving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos paquetes\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos la red neuronal\n",
    "\n",
    "Definiremos una red simple, una sola neurona. Es decir,\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(\\sum w_i \\cdot x_i + b)\n",
    "$$\n",
    "\n",
    "Y utilizaremos la función sigmoide:\n",
    "\n",
    "$$\n",
    "f(h) = \\sigma(h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función de activación\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Derivada de f\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# función h lineal\n",
    "def combinacion_lineal (X , W , b):\n",
    "    h = np.dot(W,X) + b\n",
    "    return h\n",
    "\n",
    "# Neurona\n",
    "def neurona(X,W,b):\n",
    "    return sigmoid(combinacion_lineal(X,W,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Término de error\n",
    "\n",
    "Escribe una función que calcule el término de error\n",
    "\n",
    "$$\\delta= (y-\\hat{y})f' (h) = (y-\\hat{y})f' (\\sum_i w_i x_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implementar el cálculo del término de error\n",
    "def error_term(y,W,X,b):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremento\n",
    "\n",
    "Escribe una función para determinar el incremento a uno de los pesos\n",
    "$$\\Delta w_i= \\eta \\delta x_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implementar el cálculo del incremento\n",
    "def incremento(W, X, b, eta, i, y):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar funcionamiento\n",
    "\n",
    "A continuación implementemos una red de ejemplo y verificaremos que está funcionando almenos un paso del método de descenso por gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores de ejemplo\n",
    "learning_rate = 1.0\n",
    "x = np.array([1,1])\n",
    "y = 1.0\n",
    "\n",
    "# Valores iniciales de los pesos\n",
    "w = np.array([0.1,0.2])\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza las funciones previamente definidas para calcular lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Calcular la salida de la red\n",
    "salida = None\n",
    "print('Salida:', salida)\n",
    "\n",
    "# TODO Calcula el error residual de la red\n",
    "residual = None\n",
    "print('Error:', residual)\n",
    "\n",
    "# Calcula el incremento de los pesos\n",
    "incremento = None\n",
    "print('Incremento:', incremento)\n",
    "\n",
    "# Calcula el nuevo valor del los pesos\n",
    "nw = None\n",
    "print('Nuevos pesos:', nw)\n",
    "\n",
    "# Calcula el nuevo error\n",
    "nuevo_error = None\n",
    "print('Nuevo error:', nuevo_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el nuevo error es menor que el primer error de la red entonces nuesto método de descenso está funcionando.\n",
    "\n",
    "Escribe tus conclusiones: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
